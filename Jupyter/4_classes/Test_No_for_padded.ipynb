{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a0012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "%pip install scikit-learn\n",
    "%pip install tensorflow\n",
    "%pip install matplotlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "CLASSES = [\"apple\", \"calculator\", \"water_bottle\", \"food_box\"]  # 4 classes from paper\n",
    "IMG_SIZE = (8, 8)  # Target ultra-low resolution\n",
    "DATA_PATH = \"../../../dataset/rgbd-dataset\"  # Base path to your dataset\n",
    "\n",
    "\n",
    "def get_bbox_from_mask(mask_path):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        return None\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    x,y,w,h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "    return x,y,w,h\n",
    "\n",
    "\n",
    "def load_depth_maps(class_names, data_path):\n",
    "    images, labels = [], []\n",
    "    \n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        \n",
    "        for instance_folder in sorted(os.listdir(class_path)):\n",
    "            instance_path = os.path.join(class_path, instance_folder)\n",
    "            if not os.path.isdir(instance_path):\n",
    "                continue\n",
    "\n",
    "            # Process each _depth.png and match with its _mask.png\n",
    "            for file in sorted(os.listdir(instance_path)):\n",
    "                if file.endswith(\"_depthcrop.png\"):\n",
    "                    base_prefix = file.replace(\"_depthcrop.png\", \"\")\n",
    "                    depth_path = os.path.join(instance_path, file)\n",
    "                    mask_path = os.path.join(instance_path, f\"{base_prefix}_maskcrop.png\")\n",
    "\n",
    "                    # Check if both files exist\n",
    "                    if not os.path.isfile(depth_path) or not os.path.isfile(mask_path):\n",
    "                        print(f\"Missing pair for {file}\")\n",
    "                        continue\n",
    "\n",
    "                    # Get bounding box from corresponding mask\n",
    "                    bbox = get_bbox_from_mask(mask_path)\n",
    "                    print(file)\n",
    "                    print(mask_path)\n",
    "                    if not bbox:\n",
    "                        print(f\"Invalid or empty mask for {mask_path}\")\n",
    "                        continue\n",
    "                    x, y, w, h = bbox\n",
    "\n",
    "                    # Load and crop depth image\n",
    "                    depth_img = cv2.imread(depth_path, cv2.IMREAD_ANYDEPTH)\n",
    "                    if depth_img is None or depth_img.shape == ():\n",
    "                        print(f\"Invalid depth image at {depth_path}\")\n",
    "                        continue\n",
    "\n",
    "                    height, width = depth_img.shape\n",
    "                    x1, y1 = max(0, x), max(0, y)\n",
    "                    x2, y2 = min(width, x + w), min(height, y + h)\n",
    "\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        print(f\"Invalid bbox in {depth_path}\")\n",
    "                        continue\n",
    "\n",
    "                    cropped = depth_img[y1:y2, x1:x2]\n",
    "                    resized = cv2.resize(cropped, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "                    normalized = resized.astype('float32') / 4000.0  # Adjust if needed\n",
    "\n",
    "                    images.append(normalized)\n",
    "                    labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "X, y = load_depth_maps(CLASSES, DATA_PATH)\n",
    "X = X.reshape(-1, 8, 8, 1)  # Reshape for CNN input\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f5571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir padding mirror para primera etapa de Conv\n",
    "#Formato de la matriz de entrada X[k][i][j]\n",
    "# donde k es la imagen, i es la fila de la imagen y j es la columna\n",
    "\n",
    "N = X.shape[0]\n",
    "padded_list = []\n",
    "\n",
    "for k in range(N):\n",
    "\n",
    "    mat = X[k].squeeze().copy()  # shape: (8, 8)\n",
    "\n",
    "    padded_rows = []\n",
    "    for i in range(8):\n",
    "        row = mat[i]\n",
    "        new_row = np.insert(row, 0, row[0])             # duplica primer valor\n",
    "        new_row = np.insert(new_row, len(new_row), row[-1])  # duplica último valor\n",
    "        padded_rows.append(new_row)\n",
    "    \n",
    "    mat_8x10 = np.array(padded_rows)\n",
    "\n",
    "    # Padding de filas (arriba y abajo)\n",
    "    top_row = mat_8x10[0]\n",
    "    bottom_row = mat_8x10[-1]\n",
    "    mat_10x10 = np.vstack([top_row, mat_8x10, bottom_row])\n",
    "\n",
    "    padded_list.append(mat_10x10)\n",
    "\n",
    "# Convertir lista a array numpy de shape (N, 10, 10)\n",
    "X_padded = np.array(padded_list)\n",
    "X_padded=X_padded.reshape(-1, 10, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc63bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data (70% train, 15% val, 15% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=4)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=4)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=4)\n",
    "\n",
    "print(\"\\nData loaded successfully!\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label counts:\", np.unique(y, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33935f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Input: 8x8x1 (normalized depth maps)\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=3,                  # 3 kernels (paper: \"3 channels\")\n",
    "        kernel_size=(3, 3),         # 3x3 convolutions\n",
    "        activation='relu',\n",
    "        padding='valid',             # Preserves spatial dimensions (8x8)\n",
    "        input_shape=(10, 10, 1)       # Input shape\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.25),  # 25% dropout (paper: after each conv layer)\n",
    "    \n",
    "    # Second conv layer\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=4,                  # 4 kernels (paper: \"4 channels\")\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        padding='valid'             # No padding → output shrinks to 6x6\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Classifier\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(\n",
    "        units=4,                    # 4 classes (apple, calculator, water_bottle, food_box)\n",
    "        activation='softmax'\n",
    "    )\n",
    "])\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "y_train_classes = np.argmax(y_train, axis=1)\n",
    "#model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),  # SGD (not Adam!) for stability\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Compute class weights\n",
    "best_acc=0\n",
    "best_weights = [0,0]\n",
    "\n",
    "class_weights = {0:4.0,\n",
    "                1:5.1,\n",
    "                2:2.0,\n",
    "                3:2.0}\n",
    "\n",
    "# Convert to dictionary format expected by Keras\n",
    "#class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,                     # Paper used 300 epochs\n",
    "    batch_size=32,                  # Paper: 32 for 4 classes\n",
    "    validation_data=(X_val, y_val),\n",
    "    class_weight=class_weights,     # Your computed weights\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.LearningRateScheduler(\n",
    "            lambda epoch, lr: lr * 0.5 if (epoch + 1) % 15 == 0 else lr  # LR decay every 15 epochs\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=6,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "last_train_acc = history.history['accuracy'][-1]\n",
    "if best_acc<=last_train_acc:\n",
    "    best_acc = last_train_acc\n",
    "\n",
    "print(\"Mejor precision:\",best_acc)\n",
    "#print(\"Mejor peso water bottle:\",best_weights[0])\n",
    "#print(\"Mejor peso food box:\", best_weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccb4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2704ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d5cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%pip install seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Check class distribution in true labels\n",
    "print(\"True class counts:\", np.bincount(y_true_classes))\n",
    "\n",
    "# Check class distribution in predictions\n",
    "print(\"Predicted class counts:\", np.bincount(y_pred_classes))\n",
    "\n",
    "# Check raw confusion matrix (counts)\n",
    "print(\"Raw CM (counts):\\n\", confusion_matrix(y_true_classes, y_pred_classes))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class_names=[\"apple\",\"calculator\",\"food box\",\"water bottle\"]\n",
    "# Compute confusion matrix (raw counts)\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Convert to percentages (row-wise: % of predictions per true class)\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm_percent, interpolation='nearest', cmap='Blues')\n",
    "plt.colorbar(format='%.2f%%')\n",
    "\n",
    "# Add labels\n",
    "class_names = ['apple', 'calculator', 'water_bottle', 'food_box']  # Replace with your class names\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Annotate cells with percentages\n",
    "thresh = cm_percent.max() / 2.\n",
    "for i in range(cm_percent.shape[0]):\n",
    "    for j in range(cm_percent.shape[1]):\n",
    "        plt.text(j, i, f'{cm_percent[i, j]:.1f}%',\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm_percent[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix (%)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ccf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_true_classes, return_counts=True)\n",
    "print(\"Class distribution:\", dict(zip(class_names, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6cb889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_conv_layer = model.layers[0]  # Index 0 is your first Conv2D layer\n",
    "\n",
    "# Get the weights (kernels and biases) of the first layer\n",
    "first_layer_weights = first_conv_layer.get_weights()\n",
    "\n",
    "# The weights are returned as a list where:\n",
    "# first_conv_layer_weights[0] contains the kernels (filters)\n",
    "# first_conv_layer_weights[1] contains the biases\n",
    "kernels_first_layer = first_layer_weights[0]\n",
    "biases_first_layer = first_layer_weights[1]\n",
    "\n",
    "print(\"First layer kernel:\", kernels_first_layer)\n",
    "# Should print (3, 3, 1, 3) because:\n",
    "# (kernel_height, kernel_width, input_channels, output_channels)\n",
    "\n",
    "# Similarly for the second convolutional layer\n",
    "second_conv_layer = model.layers[2]  # Index 2 (after Dropout)\n",
    "second_layer_weights = second_conv_layer.get_weights()\n",
    "kernels_second_layer = second_layer_weights[0]\n",
    "\n",
    "print(\"Second layer kernels shape:\", kernels_second_layer.shape)\n",
    "# Should print (3, 3, 3, 4) because:\n",
    "# (kernel_height, kernel_width, input_channels (from previous layer), output_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22712a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# 1. Configuración\n",
    "i = 1  # Índice del ejemplo\n",
    "layer_index = 0  # Primera capa\n",
    "\n",
    "# 2. Crear submodelo\n",
    "first_layer_model = Model(\n",
    "    inputs=model.inputs,  # Usar model.input (singular)\n",
    "    outputs=model.layers[layer_index].output\n",
    ")\n",
    "\n",
    "# 3. Obtener datos\n",
    "single_input = X_test[i:i+1].astype('float32')  # Shape (1, 10, 10, 1)\n",
    "activations = first_layer_model.predict(single_input)  # Shape (1, 8, 8, 3)\n",
    "\n",
    "biases = model.layers[0].get_weights()[1]   # shape: (3,)\n",
    "\n",
    "# 4. Mostrar entrada\n",
    "print(\"=== Entrada (10x10) ===\")\n",
    "print(f\"Ejemplo {i} - Shape: {single_input.shape}\")\n",
    "print((single_input[0,:,:,0]))  # Mostrar matriz 10x10 con 3 decimales\n",
    "\n",
    "# 5. Mostrar activaciones para cada filtro\n",
    "print(\"\\n=== Activaciones Capa Conv2D (8x8) ===\")\n",
    "print(f\"Capa: {model.layers[layer_index].name} - Filtros: {activations.shape[-1]}\")\n",
    "for j in range(activations.shape[-1]):\n",
    "    print(f\"\\nFiltro {j+1}:\")\n",
    "    print(activations[0,:,:,j])  # Matriz 8x8 con 4 decimales\n",
    "    print(f\"Valor máximo: {activations[0,:,:,j].max():.4f}\")\n",
    "    print(f\"Valor mínimo: {activations[0,:,:,j].min():.4f}\")\n",
    "    print(f\"\\nValor del bias: \",biases[j])\n",
    "for i, layer in enumerate(model.layers):\n",
    "    weights = layer.get_weights()\n",
    "    if weights:\n",
    "        print(f\"\\nLayer {i} - {layer.name}\")\n",
    "        print(\"Weights shape:\", [w.shape for w in weights])\n",
    "        \n",
    "        kernel = weights[0]\n",
    "        \n",
    "        if len(kernel.shape) == 4:  # Conv2D layer\n",
    "            # kernel shape: (height, width, input_channels, output_channels)\n",
    "            h, w, in_channels, out_channels = kernel.shape\n",
    "            print(f\"Kernel shape: {kernel.shape} (H x W x In_Ch x Out_Ch)\")\n",
    "            \n",
    "            # Show first 3x3 kernel for first input channel and first output filter\n",
    "            example_kernel = kernel[:, :, 0, 0]  # select input=0, output=0 filter\n",
    "            print(\"Example 3x3 kernel matrix (input channel 0 -> output channel 0):\")\n",
    "            print((example_kernel, 4))\n",
    "            example_kernel = kernel[:, :, 0, 1]  # select input=0, output=0 filter\n",
    "            print(\"Example 3x3 kernel matrix (input channel 0 -> output channel 1):\")\n",
    "            print((example_kernel, 4))\n",
    "            example_kernel = kernel[:, :, 0, 2]  # select input=0, output=0 filter\n",
    "            print(\"Example 3x3 kernel matrix (input channel 0 -> output channel 1):\")\n",
    "            print((example_kernel, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Get the output of the first conv layer\n",
    "model_layer_0 = Model(inputs=model.inputs, outputs=model.layers[0].output)\n",
    "\n",
    "# Pick an input\n",
    "i = 1\n",
    "input_image = X_test[i:i+1]  # shape: (1, 10, 10, 1)\n",
    "input_2d = input_image[0, :, :, 0]  # shape: (10, 10)\n",
    "\n",
    "# Get kernel and bias from filter 0\n",
    "kernels = model.layers[0].get_weights()[0]  # shape: (3, 3, 1, 3)\n",
    "biases = model.layers[0].get_weights()[1]   # shape: (3,)\n",
    "\n",
    "kernel0 = kernels[:, :, 0, 0]  # filter 0\n",
    "bias0 = biases[0]\n",
    "print(\"Biases;\\n\")\n",
    "print(biases,\"\\n\")\n",
    "# Manual convolution\n",
    "manual_output = np.zeros((8, 8))\n",
    "for row in range(8):\n",
    "    for col in range(8):\n",
    "        patch = input_2d[row:row+3, col:col+3]\n",
    "        manual_output[row, col] = np.sum(patch * kernel0) + bias0\n",
    "\n",
    "manual_output_relu = np.maximum(manual_output, 0)  # Apply ReLU\n",
    "\n",
    "# Get model prediction\n",
    "activations = model_layer_0.predict(input_image)[0]\n",
    "actual_output = activations[:, :, 0]\n",
    "\n",
    "# Compare\n",
    "print(\"Manual (with bias + ReLU):\")\n",
    "print(manual_output_relu)\n",
    "\n",
    "print(\"\\nModel output:\")\n",
    "print(actual_output)\n",
    "\n",
    "print(\"\\nDifference:\")\n",
    "print(np.abs(manual_output_relu - actual_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Asegúrate de tener la lista CLASSES definida\n",
    "CLASSES = [\"apple\", \"calculator\", \"water_bottle\", \"food_box\"]\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    pred_class = np.argmax(preds[i])\n",
    "    true_class = np.argmax(y_test[i])\n",
    "    \n",
    "    if pred_class == true_class:\n",
    "        plt.imshow(X_test[i].squeeze(), cmap='gray')\n",
    "        plt.title(f\"True: {CLASSES[true_class]}, Pred: {CLASSES[pred_class]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
