{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a0012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python\n",
    "%pip install scikit-learn\n",
    "%pip install tensorflow\n",
    "%pip install matplotlib\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters\n",
    "CLASSES = [\"apple\", \"calculator\", \"water_bottle\", \"food_box\"]  # 4 classes from paper\n",
    "IMG_SIZE = (8, 8)  # Target ultra-low resolution\n",
    "DATA_PATH = \"../../../dataset/rgbd-dataset\"  # Base path to your dataset\n",
    "\n",
    "\n",
    "def get_bbox_from_mask(mask_path):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        return None\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None\n",
    "    x,y,w,h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
    "    return x,y,w,h\n",
    "\n",
    "\n",
    "def load_depth_maps(class_names, data_path):\n",
    "    images, labels = [], []\n",
    "    \n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        \n",
    "        for instance_folder in sorted(os.listdir(class_path)):\n",
    "            instance_path = os.path.join(class_path, instance_folder)\n",
    "            if not os.path.isdir(instance_path):\n",
    "                continue\n",
    "\n",
    "            # Process each _depth.png and match with its _mask.png\n",
    "            for file in sorted(os.listdir(instance_path)):\n",
    "                if file.endswith(\"_depthcrop.png\"):\n",
    "                    base_prefix = file.replace(\"_depthcrop.png\", \"\")\n",
    "                    depth_path = os.path.join(instance_path, file)\n",
    "                    mask_path = os.path.join(instance_path, f\"{base_prefix}_maskcrop.png\")\n",
    "\n",
    "                    # Check if both files exist\n",
    "                    if not os.path.isfile(depth_path) or not os.path.isfile(mask_path):\n",
    "                        print(f\"Missing pair for {file}\")\n",
    "                        continue\n",
    "\n",
    "                    # Get bounding box from corresponding mask\n",
    "                    bbox = get_bbox_from_mask(mask_path)\n",
    "                    print(file)\n",
    "                    print(mask_path)\n",
    "                    if not bbox:\n",
    "                        print(f\"Invalid or empty mask for {mask_path}\")\n",
    "                        continue\n",
    "                    x, y, w, h = bbox\n",
    "\n",
    "                    # Load and crop depth image\n",
    "                    depth_img = cv2.imread(depth_path, cv2.IMREAD_ANYDEPTH)\n",
    "                    if depth_img is None or depth_img.shape == ():\n",
    "                        print(f\"Invalid depth image at {depth_path}\")\n",
    "                        continue\n",
    "\n",
    "                    height, width = depth_img.shape\n",
    "                    x1, y1 = max(0, x), max(0, y)\n",
    "                    x2, y2 = min(width, x + w), min(height, y + h)\n",
    "\n",
    "                    if x2 <= x1 or y2 <= y1:\n",
    "                        print(f\"Invalid bbox in {depth_path}\")\n",
    "                        continue\n",
    "\n",
    "                    cropped = depth_img[y1:y2, x1:x2]\n",
    "                    resized = cv2.resize(cropped, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "                    normalized = resized.astype('float32') / 4000.0  # Adjust if needed\n",
    "\n",
    "                    images.append(normalized)\n",
    "                    labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "X, y = load_depth_maps(CLASSES, DATA_PATH)\n",
    "X = X.reshape(-1, 8, 8, 1)  # Reshape for CNN input\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f5571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir padding mirror para primera etapa de Conv\n",
    "#Formato de la matriz de entrada X[k][i][j]\n",
    "# donde k es la imagen, i es la fila de la imagen y j es la columna\n",
    "\n",
    "N = X.shape[0]\n",
    "padded_list = []\n",
    "\n",
    "for k in range(N):\n",
    "\n",
    "    mat = X[k].squeeze().copy()  # shape: (8, 8)\n",
    "\n",
    "    padded_rows = []\n",
    "    for i in range(8):\n",
    "        row = mat[i]\n",
    "        new_row = np.insert(row, 0, row[0])             # duplica primer valor\n",
    "        new_row = np.insert(new_row, len(new_row), row[-1])  # duplica último valor\n",
    "        padded_rows.append(new_row)\n",
    "    \n",
    "    mat_8x10 = np.array(padded_rows)\n",
    "\n",
    "    # Padding de filas (arriba y abajo)\n",
    "    top_row = mat_8x10[0]\n",
    "    bottom_row = mat_8x10[-1]\n",
    "    mat_10x10 = np.vstack([top_row, mat_8x10, bottom_row])\n",
    "\n",
    "    padded_list.append(mat_10x10)\n",
    "\n",
    "# Convertir lista a array numpy de shape (N, 10, 10)\n",
    "X_padded = np.array(padded_list)\n",
    "X_padded=X_padded.reshape(-1, 10, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc63bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data (70% train, 15% val, 15% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=4)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes=4)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=4)\n",
    "\n",
    "print(\"\\nData loaded successfully!\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label counts:\", np.unique(y, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33935f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # Input: 8x8x1 (normalized depth maps)\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=3,                  # 3 kernels (paper: \"3 channels\")\n",
    "        kernel_size=(3, 3),         # 3x3 convolutions\n",
    "        activation='relu',\n",
    "        padding='valid',             # Preserves spatial dimensions (8x8)\n",
    "        input_shape=(10, 10, 1)       # Input shape\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.25),  # 25% dropout (paper: after each conv layer)\n",
    "    \n",
    "    # Second conv layer\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=4,                  # 4 kernels (paper: \"4 channels\")\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        padding='valid'             # No padding → output shrinks to 6x6\n",
    "    ),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Classifier\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(\n",
    "        units=4,                    # 4 classes (apple, calculator, water_bottle, food_box)\n",
    "        activation='softmax'\n",
    "    )\n",
    "])\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b6fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "y_train_classes = np.argmax(y_train, axis=1)\n",
    "#model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),  # SGD (not Adam!) for stability\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Compute class weights\n",
    "best_acc=0\n",
    "best_weights = [0,0]\n",
    "\n",
    "class_weights = {0:4.0,\n",
    "                1:5.0,\n",
    "                2:2.0,\n",
    "                3:2.0}\n",
    "\n",
    "# Convert to dictionary format expected by Keras\n",
    "#class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,                     # Paper used 300 epochs\n",
    "    batch_size=32,                  # Paper: 32 for 4 classes\n",
    "    validation_data=(X_val, y_val),\n",
    "    class_weight=class_weights,     # Your computed weights\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.LearningRateScheduler(\n",
    "            lambda epoch, lr: lr * 0.5 if (epoch + 1) % 15 == 0 else lr  # LR decay every 15 epochs\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=6,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "last_train_acc = history.history['accuracy'][-1]\n",
    "if best_acc<=last_train_acc:\n",
    "    best_acc = last_train_acc\n",
    "\n",
    "print(\"Mejor precision:\",best_acc)\n",
    "#print(\"Mejor peso water bottle:\",best_weights[0])\n",
    "#print(\"Mejor peso food box:\", best_weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccb4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2704ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d5cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "%pip install seaborn\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Check class distribution in true labels\n",
    "print(\"True class counts:\", np.bincount(y_true_classes))\n",
    "\n",
    "# Check class distribution in predictions\n",
    "print(\"Predicted class counts:\", np.bincount(y_pred_classes))\n",
    "\n",
    "# Check raw confusion matrix (counts)\n",
    "print(\"Raw CM (counts):\\n\", confusion_matrix(y_true_classes, y_pred_classes))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class_names=[\"apple\",\"calculator\",\"food box\",\"water bottle\"]\n",
    "# Compute confusion matrix (raw counts)\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "\n",
    "# Convert to percentages (row-wise: % of predictions per true class)\n",
    "cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm_percent, interpolation='nearest', cmap='Blues')\n",
    "plt.colorbar(format='%.2f%%')\n",
    "\n",
    "# Add labels\n",
    "class_names = ['apple', 'calculator', 'water_bottle', 'food_box']  # Replace with your class names\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Annotate cells with percentages\n",
    "thresh = cm_percent.max() / 2.\n",
    "for i in range(cm_percent.shape[0]):\n",
    "    for j in range(cm_percent.shape[1]):\n",
    "        plt.text(j, i, f'{cm_percent[i, j]:.1f}%',\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm_percent[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix (%)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ccf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_true_classes, return_counts=True)\n",
    "print(\"Class distribution:\", dict(zip(class_names, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6cb889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_conv_layer = model.layers[0]  # Index 0 is your first Conv2D layer\n",
    "\n",
    "# Get the weights (kernels and biases) of the first layer\n",
    "first_layer_weights = first_conv_layer.get_weights()\n",
    "\n",
    "# The weights are returned as a list where:\n",
    "# first_conv_layer_weights[0] contains the kernels (filters)\n",
    "# first_conv_layer_weights[1] contains the biases\n",
    "kernels_first_layer = first_layer_weights[0]\n",
    "biases_first_layer = first_layer_weights[1]\n",
    "\n",
    "print(\"First layer kernel:\", kernels_first_layer)\n",
    "# Should print (3, 3, 1, 3) because:\n",
    "# (kernel_height, kernel_width, input_channels, output_channels)\n",
    "\n",
    "# Similarly for the second convolutional layer\n",
    "second_conv_layer = model.layers[2]  # Index 2 (after Dropout)\n",
    "second_layer_weights = second_conv_layer.get_weights()\n",
    "kernels_second_layer = second_layer_weights[0]\n",
    "\n",
    "print(\"Second layer kernels shape:\", kernels_second_layer.shape)\n",
    "# Should print (3, 3, 3, 4) because:\n",
    "# (kernel_height, kernel_width, input_channels (from previous layer), output_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "22712a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "=== Entrada (10x10) ===\n",
      "Ejemplo 1 - Shape: (1, 10, 10, 1)\n",
      "[[0.26775 0.26775 0.1905  0.11325 0.18825 0.202   0.21775 0.241   0.263\n",
      "  0.263  ]\n",
      " [0.26775 0.26775 0.1905  0.11325 0.18825 0.202   0.21775 0.241   0.263\n",
      "  0.263  ]\n",
      " [0.1795  0.1795  0.074   0.167   0.177   0.17675 0.1765  0.1765  0.168\n",
      "  0.168  ]\n",
      " [0.04725 0.04725 0.1705  0.17325 0.17325 0.173   0.173   0.1495  0.05425\n",
      "  0.05425]\n",
      " [0.1335  0.1335  0.17175 0.17075 0.17025 0.16975 0.17025 0.07425 0.06175\n",
      "  0.06175]\n",
      " [0.13875 0.13875 0.1775  0.1745  0.17175 0.16925 0.16175 0.02275 0.07025\n",
      "  0.07025]\n",
      " [0.19775 0.19775 0.18575 0.18225 0.179   0.17575 0.15475 0.024   0.15025\n",
      "  0.15025]\n",
      " [0.20225 0.20225 0.19475 0.1905  0.187   0.18325 0.147   0.15325 0.202\n",
      "  0.202  ]\n",
      " [0.19975 0.19975 0.1995  0.198   0.19575 0.19225 0.19425 0.199   0.19875\n",
      "  0.19875]\n",
      " [0.19975 0.19975 0.1995  0.198   0.19575 0.19225 0.19425 0.199   0.19875\n",
      "  0.19875]]\n",
      "\n",
      "=== Activaciones Capa Conv2D (8x8) ===\n",
      "Capa: conv2d - Filtros: 3\n",
      "\n",
      "Filtro 1:\n",
      "[[ 0.22587946  0.16063276  0.11374345  0.04804084  0.16679946  0.20094797\n",
      "   0.23419866  0.26417908]\n",
      " [ 0.0605112   0.13348117  0.0398961   0.08164975  0.14139238  0.14790842\n",
      "   0.11139038  0.07502988]\n",
      " [-0.         -0.          0.04719004  0.10684994  0.11270437  0.06382671\n",
      "  -0.         -0.        ]\n",
      " [-0.         -0.          0.11043915  0.1078603   0.10245225 -0.\n",
      "  -0.         -0.        ]\n",
      " [ 0.08342907  0.07704833  0.12410304  0.11628947  0.10007337 -0.\n",
      "  -0.         -0.        ]\n",
      " [ 0.1413289   0.14058283  0.14700928  0.1359689   0.10431388  0.00388661\n",
      "   0.0419322  -0.        ]\n",
      " [ 0.19468722  0.19041792  0.17310223  0.16222712  0.13795778  0.1037266\n",
      "   0.09350827  0.03452539]\n",
      " [ 0.20024058  0.19678238  0.1880481   0.17873368  0.16442218  0.15902063\n",
      "   0.1541942   0.17030063]]\n",
      "Valor máximo: 0.2642\n",
      "Valor mínimo: -0.0000\n",
      "\n",
      "Filtro 2:\n",
      "[[ 0.1530559   0.0070655   0.01862994  0.11223692  0.15857959  0.202366\n",
      "   0.2475316   0.2638883 ]\n",
      " [-0.         -0.          0.03270051  0.11080557  0.11914349  0.13419968\n",
      "   0.12635988  0.10625654]\n",
      " [-0.         -0.          0.08695877  0.076828    0.07489419  0.0383141\n",
      "  -0.         -0.        ]\n",
      " [ 0.00653398  0.06371328  0.0733934   0.06988364  0.06666106 -0.\n",
      "  -0.         -0.        ]\n",
      " [ 0.06421694  0.08324653  0.07999349  0.07371211  0.06123883 -0.\n",
      "  -0.         -0.        ]\n",
      " [ 0.11427289  0.11721033  0.09744275  0.0879845   0.05677581 -0.\n",
      "  -0.         -0.        ]\n",
      " [ 0.13942033  0.12763733  0.1192714   0.10991812  0.06783909 -0.\n",
      "   0.03274897  0.11111128]\n",
      " [ 0.1484701   0.1414454   0.13578737  0.12744147  0.09821922  0.09383231\n",
      "   0.14073974  0.15922779]]\n",
      "Valor máximo: 0.2639\n",
      "Valor mínimo: -0.0000\n",
      "\n",
      "Filtro 3:\n",
      "[[-0.00000000e+00 -0.00000000e+00  6.87307715e-02  1.10296309e-01\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
      " [ 8.92078876e-03  2.61443853e-02  9.77715254e-02  5.86897731e-02\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00]\n",
      " [ 2.33039320e-01  1.66789174e-01  1.05591714e-01  8.74102116e-03\n",
      "  -0.00000000e+00 -0.00000000e+00  3.65785360e-02  1.68304622e-01]\n",
      " [ 2.50993133e-01  1.85739636e-01  3.19576263e-03  4.42916155e-03\n",
      "   6.83677197e-03 -0.00000000e+00  1.32145643e-01  3.33785743e-01]\n",
      " [ 7.50491023e-02  5.45496941e-02 -0.00000000e+00 -0.00000000e+00\n",
      "   3.49104404e-04  2.20942497e-03  2.00080663e-01  4.25349951e-01]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00  3.05302143e-02  1.75768852e-01  3.46213251e-01]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00  6.65032864e-03  7.06174970e-02  1.42485470e-01]\n",
      " [-0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00\n",
      "  -0.00000000e+00 -0.00000000e+00 -0.00000000e+00 -0.00000000e+00]]\n",
      "Valor máximo: 0.4253\n",
      "Valor mínimo: -0.0000\n",
      "\n",
      "Layer 0 - conv2d\n",
      "Weights shape: [(3, 3, 1, 3), (3,)]\n",
      "Kernel shape: (3, 3, 1, 3) (H x W x In_Ch x Out_Ch)\n",
      "Example 3x3 kernel matrix (input channel 0 -> output channel 0):\n",
      "(array([[ 0.6112603 ,  0.14949825,  0.25515392],\n",
      "       [ 0.8014766 , -0.08438794,  0.34237343],\n",
      "       [ 0.27291304,  0.5056705 ,  0.42247623]], dtype=float32), 4)\n",
      "Example 3x3 kernel matrix (input channel 0 -> output channel 1):\n",
      "(array([[-0.14316535,  0.3289074 ,  0.747816  ],\n",
      "       [ 0.30346522,  0.292145  ,  0.6258118 ],\n",
      "       [ 0.42327175,  0.12158056,  0.22500373]], dtype=float32), 4)\n",
      "Example 3x3 kernel matrix (input channel 0 -> output channel 1):\n",
      "(array([[-0.9973611 , -0.21623789, -0.13520855],\n",
      "       [-0.9868934 , -0.45960158,  0.05327905],\n",
      "       [-0.5879533 , -0.5180387 ,  0.17444253]], dtype=float32), 4)\n",
      "\n",
      "Layer 2 - conv2d_1\n",
      "Weights shape: [(3, 3, 3, 4), (4,)]\n",
      "Kernel shape: (3, 3, 3, 4) (H x W x In_Ch x Out_Ch)\n",
      "Example 3x3 kernel matrix (input channel 0 -> output channel 0):\n",
      "(array([[-0.01877646,  0.11226276, -0.05914106],\n",
      "       [-0.4414905 , -0.23155859, -0.02479265],\n",
      "       [-0.2173934 , -0.2715974 , -0.27247334]], dtype=float32), 4)\n",
      "Example 3x3 kernel matrix (input channel 0 -> output channel 1):\n",
      "(array([[ 0.261284  , -0.12309594,  0.1339922 ],\n",
      "       [ 0.2738981 ,  0.44257593,  0.29079324],\n",
      "       [ 0.15775368, -0.05257329,  0.36544025]], dtype=float32), 4)\n",
      "Example 3x3 kernel matrix (input channel 0 -> output channel 1):\n",
      "(array([[-0.34603432, -0.07605162, -0.2724247 ],\n",
      "       [ 0.11507207, -0.17770615,  0.10412519],\n",
      "       [-0.21325706, -0.02369724, -0.31328094]], dtype=float32), 4)\n",
      "\n",
      "Layer 5 - dense\n",
      "Weights shape: [(144, 4), (4,)]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "# 1. Configuración\n",
    "i = 1  # Índice del ejemplo\n",
    "layer_index = 0  # Primera capa\n",
    "\n",
    "# 2. Crear submodelo\n",
    "first_layer_model = Model(\n",
    "    inputs=model.inputs,  # Usar model.input (singular)\n",
    "    outputs=model.layers[layer_index].output\n",
    ")\n",
    "\n",
    "# 3. Obtener datos\n",
    "single_input = X_test[i:i+1].astype('float32')  # Shape (1, 10, 10, 1)\n",
    "activations = first_layer_model.predict(single_input)  # Shape (1, 8, 8, 3)\n",
    "\n",
    "# 4. Mostrar entrada\n",
    "print(\"=== Entrada (10x10) ===\")\n",
    "print(f\"Ejemplo {i} - Shape: {single_input.shape}\")\n",
    "print((single_input[0,:,:,0]))  # Mostrar matriz 10x10 con 3 decimales\n",
    "\n",
    "# 5. Mostrar activaciones para cada filtro\n",
    "print(\"\\n=== Activaciones Capa Conv2D (8x8) ===\")\n",
    "print(f\"Capa: {model.layers[layer_index].name} - Filtros: {activations.shape[-1]}\")\n",
    "for j in range(activations.shape[-1]):\n",
    "    print(f\"\\nFiltro {j+1}:\")\n",
    "    print(activations[0,:,:,j])  # Matriz 8x8 con 4 decimales\n",
    "    print(f\"Valor máximo: {activations[0,:,:,j].max():.4f}\")\n",
    "    print(f\"Valor mínimo: {activations[0,:,:,j].min():.4f}\")\n",
    "for i, layer in enumerate(model.layers):\n",
    "    weights = layer.get_weights()\n",
    "    if weights:\n",
    "        print(f\"\\nLayer {i} - {layer.name}\")\n",
    "        print(\"Weights shape:\", [w.shape for w in weights])\n",
    "        \n",
    "        kernel = weights[0]\n",
    "        \n",
    "        if len(kernel.shape) == 4:  # Conv2D layer\n",
    "            # kernel shape: (height, width, input_channels, output_channels)\n",
    "            h, w, in_channels, out_channels = kernel.shape\n",
    "            print(f\"Kernel shape: {kernel.shape} (H x W x In_Ch x Out_Ch)\")\n",
    "            \n",
    "            # Show first 3x3 kernel for first input channel and first output filter\n",
    "            example_kernel = kernel[:, :, 0, 0]  # select input=0, output=0 filter\n",
    "            print(\"Example 3x3 kernel matrix (input channel 0 -> output channel 0):\")\n",
    "            print((example_kernel, 4))\n",
    "            example_kernel = kernel[:, :, 0, 1]  # select input=0, output=0 filter\n",
    "            print(\"Example 3x3 kernel matrix (input channel 0 -> output channel 1):\")\n",
    "            print((example_kernel, 4))\n",
    "            example_kernel = kernel[:, :, 0, 2]  # select input=0, output=0 filter\n",
    "            print(\"Example 3x3 kernel matrix (input channel 0 -> output channel 1):\")\n",
    "            print((example_kernel, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Asegúrate de tener la lista CLASSES definida\n",
    "CLASSES = [\"apple\", \"calculator\", \"water_bottle\", \"food_box\"]\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    pred_class = np.argmax(preds[i])\n",
    "    true_class = np.argmax(y_test[i])\n",
    "    \n",
    "    if pred_class == true_class:\n",
    "        plt.imshow(X_test[i].squeeze(), cmap='gray')\n",
    "        plt.title(f\"True: {CLASSES[true_class]}, Pred: {CLASSES[pred_class]}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
